# Lecture 3

- 손실함수
- 최적화

가장 좋은 행렬 W를 어떻게 구할까?
어떻게 Training Data를 활용해야 할까?

우리가 구한 W가 좋은지 안좋은지를 정량화해야 한다.
그리고 이를 해주는 것이 “손실 함수(Loss function)”이다.

“최적화 (Optimization)”는 손실 함수가 계산해준 점수를 최소화하기 위해 가중치(W)를 조금씩 수정해나가는 것이다. 

**손실 함수는 훈련 데이터에만 적용됩니다.** 그 이유는 손실 함수(Loss Function)의 주된 목적이 모델이 얼마나 잘 '학습'하고 있는지를 평가하는 것이기 때문입니다. 모델은 훈련 데이터를 보면서 손실을 줄이는 방향으로 가중치(W)를 계속해서 조정해 나갑니다.

Linear Classifier가 왜 Linear인지 이해가 필요

마진 크기 0 혹은 100으로 하면 어떤 문제 발생?

정규화항이 어떻게 문제를 해결하는지?

# 1. Loss Function

![image.png](image.png)

$L$
→ 모델의 총 손실(Total Loss)를 의미한다. 이 값을 최소화하는 것이 목표이다.

$\frac{1}{N}∑_i$
→ 모든 학습 데이터에 대한 손실을 더하고 전체 데이터의 개수 $N$을 나눈다. 즉, 모든 학습 데이터에 대한 손실의 평균값을 계산한다.

$f(x_i, W)$
→ classifier(분류기) 함수이다. 이미지 $x_i$를 입력으로 받고, 가중치($W$)를 사용하여 각 클래스에 대한 점수를 출력

$L_i(f(x_i, W), y_i)$
→ 개별 학습 데이터 $i$에 대한 개별 손실(individual Loss)이다.

- $y_i$는 이미지 $x_i$에 대한 정답 라벨(integer label)이다.
- $L_i(…)$는 classifier가 예측한 점수와 $y_i$ (정답 라벨)을 비교하여, 얼마나 틀렸는지를 계산하는 함수이다.

그래서 $L_i$는 어떻게 계산할건데??

## 1-1) multi-class SVM loss function

![image.png](image%201.png)

**다중 클래스 SVM(Multi-class Support Vector Machine) 손실 함수**는 모델이 정답 클래스의 점수를 오답 클래스의 점수보다 일정 **마진(margin)** 이상으로 높게 예측하도록 유도한다.
$s_{y_i}$
→ 정답 클래스($y_i$)에 대한 예측 점수
ex) 고양이 이미지를 학습할 때 cat에 대한 점수

$s_j$
→ 오답 클래스($j$)에 대한 예측 점수
ex) $j=frog$일 때, 고양이 이미지를 학습할 때 frog에 대한 점수

$∑_{j\ne{y_i}}$
→ 정답 클래스를 제외한 **모든 오답 클래스에 대해 합산**하겠다는 의미

- 만약 정답 점수 $s_{y_i}$가 오답 점수 $s_j$보다 1 이상 크면 손실은 0이고, 그렇지 않다면 $s_j - s_{y_i} + 1$만큼의 손실이 더해진다.
- 즉 **“정답 점수가 오답 점수보다 최소한 1점은 더 높아야 한다”** 라는 의미가 담김

$max(0, s_j - s_{y_i} + 1)$
→ 이 부분이 SVM loss function의 핵심

- **마진(margin):** $+1$은 모델이 정답 클래스의 점수가 오답 클래스의 점수보다 최소 1점 높게 예측하도록 하는 **‘안전 마진(safty margin)’**임
- **손실 계산:**
    - 결과가 0보다 크면, 그 값이 손실
    - 결과가 0보다 작거나 같으면, 손실이 0
    이는 모델이 예측을 잘하고 있다는 의미

**“정답 점수가 오답 점수보다 충분히 크면(≥1 차이) 손실은 0. 그렇지 않으면 그 부족한 만큼 벌점(손실) 부여.”**

<aside>
💡

정답: cat 
정답 점수 $s_{y_i} = 3.2$

- car 점수 = $5.1$
    
    $5.1−3.2+1=2.9(>0)$
    
    → 손실 2.9 발생
    
- frog 점수 = $-1.7$
    
    $−1.7−3.2+1=−3.9(<0)$
    
    → 손실 0
    
</aside>

### 그래프

![그래프가 경첩처럼 꺾여 있어서 hinge loss라고 불림](image%202.png)

그래프가 경첩처럼 꺾여 있어서 hinge loss라고 불림

**X축:** $S_{y_i}$
**Y축:** Loss 값

정답 점수($S_{y_i}$)가 낮을 때는 Loss가 크다.
정답 점수가 늘아날 수록 Loss가 선형적으로 작아진다.
정답 점수가 오답 점수($S_j$)보다 $+1$(Safty margin) 클 때 Loss가 0이 된다.
(정답 점수가 오답 점수보다 1 이상 크면 → 손실 0이라는 뜻) 
그 이후로 이미 안전 마진을 확보했기 때문에 정답 점수를 올려도 Loss가 더 이상 줄지 않는다. (항상 0을 유지)

### 계산 결과

![image.png](image%203.png)

![image.png](image%204.png)

![image.png](image%205.png)

![image.png](image%206.png)

classifier가 5.3만큼 이 Train set을 구리게 분류하고 있다는 “정량적 지표”가 된다.

- 손실 값(2.9, 12.9)은 W가 잘못된 정도를 알려줄 뿐, 절대 숫자는 중요하지 않음.
    
    진짜 중요한 건:
    
    1. **정답 점수 vs 오답 점수 차이** (상대적인 관계)
    2. 그 차이가 마진(1) 이상인지 아닌지
- 학습은 결국 **손실을 줄이는 방향(정답 ↑, 오답 ↓)**으로 W를 바꾸는 과정이다.

### 흐름

1. **W로 점수 계산**: $s=Wx$
2. **SVM Loss로 평가**: 정답 점수가 오답보다 +1 이상 큰지 확인
3. **손실 값 집계**: 각 샘플의 손실 → 평균
4. **경사하강법으로 W 수정**: 손실이 큰 쪽 샘플을 반영해서 W를 업데이트

→ 결과적으로 **정답 점수는 올라가고, 오답 점수는 내려가는 방향**으로 학습됨.

<aside>
💡

**Q.** 보통은 행렬 W를 임의의 작은 수로 초기화시킨다. 그러면 처음 학습 시에는 결과 스코어가 임의의 일정한 값을 가지게 된다.
그렇다면 만약 모든 스코어 S가 거의 “0에 가깝고” 혹은 “값이 서로 거의 비슷하다면”
Multicalss SVM에서 Loss는 어떻게 될까? (Margin = 1 일 경우)

계산 결과 손으로 써보기

**A.** 한 샘플의 손실 $L_i$는 각 오답 클래스마다 약 1의 손실이 발생하므로, 전체적으로 $L_i≈C−1$이 된다. 따라서 전체 평균 손실 $L$도 $C−1$ 근처가 된다. ($C$는 클래스의 개수)
학습을 시작할 때 만약 Loss 값이 $C - 1$ 근처가 나오지 않았다면, 구현에 버그가 있을 가능성이 높다. 따라서 이러한 초기 Loss값은 “제대로 시작됐는지” 확인하는 체크포인트 역할을 한다.
—————————————————
**Q.** 만약 아래와 같이 Loss function을 제곱 항으로 바꾸면 어떻게 될까?

![image.png](image%207.png)

**A.** Loss function에 제곱을 추가하면 모델이 예측 오류에 반응하는 방식이 근본적으로 달라지게 된다. 이는 오차에 대한 패널티를 *비선형적(nonlinear)* 으로 부여하는 것과 같다.

기존 hinge loss는 오차와 손실 값이 선형적으로 비례했기 때문에, **조금 틀린 경우와 많이 틀린 경우를 크게 구분하지 않았다.**

반면 **squared hinge loss**는 손실을 제곱하기 때문에,

- 작은 오차는 상대적으로 덜 중요하게 취급하고,
- 큰 오차는 훨씬 더 큰 패널티로 반영한다.

즉, 모델은 **심각하게 잘못 분류한 경우를 우선적으로 보완**하도록 학습 방향이 달라진다.

이는 우리가 “어떤 종류의 오류를 더 중요하게 다룰지”를 손실 함수 설계를 통해 결정한다는 것을 보여준다.
(손실 함수를 어떻게 정의하느냐에 따라 모델이 **작은 오류를 줄이는 데 집중할지, 큰 오류를 줄이는 데 집중할지**가 달라진다는 뜻)

</aside>

### numpy code

![image.png](image%208.png)

1. **점수 계산**: 가중치 행렬 `W`와 입력 이미지의 열 벡터 `x`를 내적(dot product)하여 각 클래스에 대한 예측 점수를 담은 열 벡터 `scores`를 계산
2. **마진 손실 계산**: NumPy의 브로드캐스팅 기능을 활용해 `scores` 벡터의 모든 요소에 대해 `(점수 - 정답 스코어 + 1)` 연산을 한 번에 수행. 
이 결과가 `margins` 벡터에 저장되고,  `np.maximum` 함수로 인해, 마진을 충족하는 경우에는 손실이 0이 됨
3. **정답 클래스 손실 제거**: `margins[y] = 0` 코드를 사용해, 정답 클래스 자체에 대한 손실은 계산에서 제외하도록 명시적으로 0으로 만듬
4. **최종 손실 합산**: `np.sum` 함수로 `margins` 벡터의 모든 값을 더하여, 해당 이미지($L_i$)에 대한 최종 손실을 계산
5. 값 반환

## 1-2) 과적합(Overfitting) & 정규화(Regularization)

![image.png](image%209.png)

손실 함수는 **정답 점수가 오답 점수보다 마진(margin) 이상으로 높다**는 조건만 만족하면 손실을 0으로 계산한다. 따라서 이미 이 조건을 만족하는 W가 있다면, 그 W를 두 배, 세 배로 키우더라도 마진은 여전히 유지되거나 더 커지므로 손실 값은 계속 0이 된다.
따라서 손실을 0으로 만드는 W는 무수히 많다.

이러한 W들은 Train 데이터에서만 잘 작동하게 된다. 따라서 Test 데이터와 같은 새로운 데이터도 좋은 성능을 낼 것이라고 보장할 수가 없다. 오히려 실제 데이터에서는 이해할 수 없는 엉뚱한 결과를 낼 수도 있다.

이것이 바로 **과적합(overfitting)** 문제이다. 모델이 훈련 데이터의 잡음까지 외워버려서, 새로운 데이터를 만나면 제대로 예측하지 못하는 현상이다.

![image.png](image%2010.png)

예를 들어 다음과 같이 학습 데이터(파란 점)들이 분포되어 있다고 하자.
분류기는 모든 Trainning Data를 완벽하게 분류하기 위해 구불구불한 곡선을 만들 것이다.
하지만 이는 Test Data에 대해서는 전혀 고려가 되지 않은 상황이다.

![image.png](image%2011.png)

다음과 같이 새로운 데이터(초록색 네모)들이 들어온다면 구불구불한 곡선은 완전히 틀린 것이 된다. 사실 우리가 필요한건 초록색 선인 것이다.
이러한 문제를 해결하는 방법을 **Regularization(정규화)**이라고 한다.

$Loss=Data Loss+λR(W)$

여기서 $R(W)$는 모델이 좀 더 단순한 $W$를 선택하도록 도와준다. 즉 모델의 복잡도에 패널티를 주는 항이다. 
$λ$는 두 항의 비중을 조절하는 하이퍼 파라미터이다.

정리하면 다음과 같다.

- Regularization은 모델에게 이렇게 말하는 것과 같다:
    - “훈련 데이터에 잘 맞추는 건 좋은데, **너무 복잡한 방식으로 맞추면 벌점 줄 거야**.”
    (정규화 항은 손실을 인위적으로 키워서, 복잡한 W가 최적해가 되지 못하게 만든다.)
- 결과적으로 모델은 **단순하면서도 데이터에 잘 맞는 해**를 찾게 된다.
- 그래서 구불구불한 고차 다항식 대신, **낮은 차수(단순한) 다항식**을 더 선호하게 된다.

### L1 & L2 Regularization

![image.png](image%2012.png)

$W_{k,j}$
→ 행렬 W의 k번째 행, j번째 열에 있는 **하나의 가중치 값**을 의미

$∑_k∑_j$
→ 행렬 W의 **모든 가중치 값**에 대해 합산하라는 뜻

L2 regularization은 “모든 가중치 값을 각각 제곱한 다음, 그 제곱한 값들을 모두 더하라”는 뜻이고,
L1 regularization은 "모든 가중치 값의 절댓값을 구한 다음, 그 절댓값들을 모두 더하라”는 뜻이다.

다음과 같은 데이터가 있다고 가정하자.

- **입력 데이터 x**: `[1, 1, 1, 1]`
- **가중치 W1**: `[1, 0, 0, 0]`
- **가중치 W2**: `[0.25, 0.25, 0.25, 0.25]`

$W1$과 $W2$는 모두 입력 $x$와의 내적($W⋅x$) 결과가 $1$로 동일하기 때문에, 선형 분류기의 예측 결과는 같다. 하지만 L2 Regularizaton의 관점에서는 두 가중치의 복잡도가 다르게 측정된다.

$|W_1|_2^2 = 1^2 + 0^2 + 0^2 + 0^2 = 1$

$|W_2|_2^2 = 0.25^2 + 0.25^2 + 0.25^2 + 0.25^2 = 0.0625 \times 4 = 0.25$

즉 L2 Regularizaton의 경우에는 norm을 계산한 결과가 $W2$가 더 작기 때문에, $W1$보다 $W2$를 더 선호하게 된다.

**이는 L2 Regularization은 가중치의 값이 하나의 원소에 집중된 $W1$보다 가중치가 여러 원소에 고르게 분산된 $W2$를 더 단순한 모델로 선호한다는 것을 알 수 있다.**
(L2 Regularization은 가중치 값이 한두 개의 원소에 집중된 형태보다, 여러 원소에 걸쳐 고르게 분산된 형태를 더 단순하고 안정적인 모델로 본다.

반대로 L1 Regularization은 W1처럼 일부 원소에 집중된 가중치를 선호하는데, 이는 특정 입력에 더 민감하게 반응하고 일반화 성능은 떨어질 수 있음을 의미한다.)

이처럼 머신러닝에서 **Regularization**은 단순히 수학적 테크닉이 아니라, 우리가 **“복잡성”을 어떻게 정의하느냐**에 대한 철학적 선택이다. 어떤 문제에서는 가중치가 크지 않고 고르게 분산된 모델이 더 단순할 수 있고(L2), 또 다른 문제에서는 불필요한 가중치를 과감히 0으로 만들어 희소성을 확보하는 모델이 더 단순할 수 있다(L1).

따라서 중요한 것은 **“복잡하다”의 기준을 문제와 데이터, 그리고 모델의 특성에 맞게 정의하는 것**이다. 우리가 선택한 정의가 곧 손실 함수와 정규화 항을 통해 모델에 전달되고, 그 결과 모델은 우리가 원하는 방향으로 학습하게 된다.

결국, 좋은 모델을 만드는 핵심은 단순히 데이터를 잘 맞추는 것을 넘어, **우리 문제에 적합한 복잡성의 기준을 세우고 그것을 반영한 정규화 전략을 세우는 것**이라고 할 수 있다.

## 1-3) Softmax Classifier

![image.png](image%2013.png)

Softmax Classifier Loss Function은 모델의 예측 점수(scores)를 **'확률'**로 변환한 다음, 정답 클래스에 해당하는 확률이 1에 가깝도록 유도하는 손실 함수이다.

모델이 예측한 점수 벡터 $s=[s_1,s_2,...,s_C]$ (C는 클래스 개수)를 다음의 **Softmax 함수**에 넣어 확률 분포 P를 계산한다.

$P(Y=k∣X=x_i)=\frac{e^{s_k}}{∑_je^{s_j}}$

- **지수 함수(**$e^{s_k}$**)**: 점수 $s_k$에 지수를 취해 모든 값을 양수로 만든다.
- **정규화(**$∑e^{s_j}$**)**: 모든 클래스의 지수 값의 합으로 나누어, 모든 확률의 합이 1이 되도록 정규화한다.
- **결과**: 이렇게 얻은 P는 '모델이 이 이미지를 클래스 $k$라고 예측할 확률'을 의미한다.

예: 고양이 3.2, 자동차 5.1, 개구리 -1.7 → softmax를 거치면
고양이 확률 0.1, 자동차 0.9, 개구리 0.0 (이런 식)

$L_i=−logP(Y=y_i∣X=x_i)$

- 정답 클래스의 확률이 높으면 $L_i$의 값이 작아짐 (Loss ↓)
- 정답 클래스의 확률이 낮으면 $L_i$의 값이 커짐 (Loss ↑)

![image.png](image%2014.png)

$log$를 쓰는건 수학적 계산을 쉽게 하도록 하기 위해서이고,
$log$에 마이너스($-$)를 붙인 이유는 확률이 올라갈 수록 Loss값이 낮아지도록 하기 위해서이다.

그래프를 통해 이론상 softmax loss의 최댓값은 무한대 최솟값은 0임을 확인할 수 있다.

![image.png](image%2015.png)

만약 고양이의 이미지를 넣었을 때 Loss 값이 0이 나오기 위해서는 cat의 스코어가 몇이어야 할까? 아마 cat의 점수는 양의 무한대에 수렴해야하고, 다른 class의 점수는 음의 무한대에 수렴해야 할 것이다. 하지만 컴퓨터의 “유한 정밀도”라는 특성상 무한대라는 개념이 존재하지 않는다. 따라서 사실 softmax의 loss값은 완전한 0으로 출력될 수 없다.

### 디버깅 전략

1. **Softmax 확률 계산**: 손실을 계산하기 위해 먼저 예측 점수(s)를 확률(P)로 변환해야 한다
$P(Y=k∣X=x_i)=\frac{e^{s_k}}{∑_je^{s_j}}$
2. **점수 대입**: 초기에는 모든 점수 $s_k$가 0에 가깝다고 가정한다.
    - $e^{s_k}≈e^0=1$
    - 따라서 분자($e^{s_{k}}$)는 약 1이 된다
    - 분모($∑_je^{s_j}$)는 모든 클래스의 지수 값의 합이므로, 클래스 개수 $C$에 가까워진다.
    - 즉, 모든 클래스를 **1/C의 확률**로 예측하는 것과 같다. 이는 무작위 추측(random guess)과 동일한 상태이다.
3. **손실(**$L_i$**) 계산**: 이 확률을 손실 함수에 대입한다.
$L_i=−logP(Y=k∣X=x_i)≈−log(\frac{1}C) = logC$

따라서 초기 Loss는 $logC$가 된다.

만약 모델을 초기화하고 첫 번째 학습 반복(iteration)을 수행했을 때, 손실 값이 $logC$와 다르다면, 손실 함수나 모델 구현에 버그가 있을 가능성이 높다.

## 1-4) 두 손실함수 비교

![image.png](image%2016.png)

multi-class SVM loss에서는 정답 이미지의 스코어가 다른 클래스보다 훨씬 높으면 정답 이미지의 스코어를 조금 바꾼다고 해서 SVM Loss의 결과가 변하지 않는다. 왜냐하면 SVM Loss는 오직 정답과 그 외 클래스의 마진이 얼마나 되는지에만 관심이 있기 때문이다.

하지만 softmax loss는 언제나 확률을 1로 만들기 위해 노력한다. 따라서 정답 스코어가 충분히 높고, 다른 클래스 스코어가 충분히 낮음에도 불구하고 softmax는 최대한 정답 클래스에 확률을 몰아 넣으려고 할 것이다. 즉 정답 클래스는 양의 무한대로, 그 외 클래스는 음의 무한대로 보내려 할 것이다.

이것이 두 손실 함수 간의 차이점이다.

정리하자면, SVM의 경우 일정 선(margin)을 넘기만 하면 더 이상 성능 개선에 신경을 쓰지 않지만, softmax는 항상 더 좋은 성능을 추구할 것이다.

## 1-5) 전체 흐름

![image.png](image%2017.png)

- **데이터 준비**
    - 입력 데이터 x와 정답 레이블 y가 있다.
- **모델의 예측 (Linear Classifier)**
    - 입력 x로부터 스코어를 계산하기 위해 **선형 분류기(linear classifier)**를 사용한다.
    - 이 스코어는 각 클래스에 대한 모델의 "예측 점수"이다.
- **손실 함수 (Loss Function)**
    - Softmax Loss, SVM Loss 등을 사용해 모델이 얼마나 정답과 차이가 나는지, 즉 **예측이 얼마나 구린지**를 수치로 측정한다.
- **정규화 (Regularization)**
    - 모델이 지나치게 복잡해지는 것을 막기 위해 손실 함수에 **정규화 항(regularization term)**을 추가한다.
    - 이를 통해 모델이 단순하면서도 잘 작동하도록 유도한다.

여기까지가 Supervised learning이라 부르는 것에 전반적인 개요이다.
하지만 여전히 어떻게 실제 Loss를 줄이는 W를 찾을 수 있는지에 대한 의문이 남아있다.

여기에 대한 답으로는 **“Optimization(최적화)”**이다.

# 2. Optimization

![image.png](image%2018.png)

최적화를 이해하기 쉽게 강의에서는 거대한 계곡을 걷는 사람에 비유한다. 이때 산과 계곡 같은 지형은 파라미터 $W$의 공간을, 내가 서 있는 위치의 높이는 손실 함수(Loss)의 값을 의미한다. 우리의 목표는 이 계곡에서 가장 낮은 지점, 즉 손실이 최소가 되는 지점을 찾는 것이다.

한 가지 단순한 방법은 임의 탐색(random search)이다. 말 그대로 눈 감고 이리저리 걸어 다니며 발에 밟히는 곳을 확인하는 것처럼, 무작위로 여러 $W$를 뽑아보고 그중 Loss가 가장 낮은 값을 선택하는 방식이다. 그러나 이는 비효율적이며, 실제로는 CIFAR-10 같은 문제에서도 15% 정도의 낮은 성능밖에 내지 못한다.

더 나은 방법은 지역적인 기하학적 특성(local geometry)을 활용하는 것이다. 사람이 두 발로 땅의 경사를 느끼며 어느 쪽이 더 낮은 방향인지 판단하듯, 최적화 알고리즘은 현재 위치에서 손실 함수의 기울기(gradient)를 계산하고 그 방향으로 한 걸음씩 나아간다. 이런 과정을 반복하면 결국 계곡의 바닥, 즉 Loss가 최소가 되는 지점에 도달할 수 있다.

이 비유의 핵심은 최적화가 한 번에 답을 찾는 과정이 아니라, 현재 위치의 경사를 이용해 조금씩 내려가는 반복적(iterative) 과정이라는 점을 강조하는 것이다. 무작정 이리저리 움직이는 것보다, 경사 정보를 활용하는 방식(경사하강법, Gradient Descent)이 훨씬 효율적이고 똑똑한 방법임을 보여준다.

## 2-1) Gradient Descent (경사 하강법)

<aside>
💡

**기울기 (Slope)
:** 기울기는 1차원 함수($y=f(x)$)에서 곡선의 특정 지점에서의 가파른 정도를 나타냅니다. 즉, 변수 x가 변할 때 함수 y가 얼마나 빠르게 변하는지를 나타내는 단일한 **스칼라 값**입니다.

**경사도 (Gradient)
:** 경사도는 다차원 함수($z=f(x_1,x_2,...,x_n)$)에서 사용되며, 각 변수 방향으로의 기울기를 모두 모아놓은 **벡터**입니다. 경사도 벡터는 함수가 가장 빠르게 증가하는 방향을 가리키며, 그 벡터의 크기는 증가하는 속도를 나타냅니다.

- Gemini -

</aside>

![image.png](image%2019.png)

1차원 함수 $y=f(x)$를 미분하면, 어떤 점 $x$에서의 **기울기(slope)**를 얻을 수 있다.

마찬가지로 다차원 함수 $y=f(x_1, x_2,…,x_n)$에서는 각 변수에 대해 편미분을 구하고, 그 값들을 하나의 벡터로 모을 수 있다. 이렇게 얻은 벡터를 **경사도(Gradient)**라고 하며, 이는 각 변수 방향에서의 기울기를 담고 있다.

$∇f=[\frac{df}{dx_1}, \frac{df}{dx_2},...,\frac{df}{dx_n}]$

이러한 Gradient 벡터는 **함수 값이 가장 크게 증가하는 방향**을 가리킨다. 따라서 경사도 벡터의 반대 방향인 $-∇f$는 함수 값이 **가장 크게 감소하는 방향**을 나타낸다.
또한, 만약 특정 방향 $u$로 이동했을 때 함수 값이 얼마나 변하는지 알고 싶다면, 그 방향의 변화율은 Gradient와 방향(단위) 벡터 $u$의 내적으로 계산할 수 있다. 이를 방향 **도함수(direction derivative)**라고 부른다.

우리가 특정 방향에서 함수 값이 얼마나 변하는지를 확인하는 이유는, 지금 구한 gradient가 그 방향으로 움직일 때 손실 감소에 얼마나 효과적인지를 알고 싶기 때문이다. Gradient 자체는 “가장 빠르게 감소하는 방향”을 알려주지만, 실제로는 우리가 다른 방향(예: 제약 조건 때문에 허용된 방향, 혹은 다른 최적화 알고리즘이 제시하는 방향)으로 움직여야 할 때가 있다. 이때 gradient와 그 방향 벡터의 내적(방향 도함수)을 계산하면, 그 방향이 얼마나 잘 작동하는지, 즉 손실을 줄이는 데 얼마나 기여할 수 있는지를 알 수 있다.

![Gradient는 함수에서 증가하는 방향에 위치한다.](image%2020.png)

Gradient는 함수에서 증가하는 방향에 위치한다.

![다음은 Loss 함수 그래프이다. 임의의 점에 W를 설정하고 - gradient 방향으로 움직여서 빨간 구역(Loss = 0)에 도달하는 것을 목표로 한다.](image%2021.png)

다음은 Loss 함수 그래프이다. 임의의 점에 W를 설정하고 - gradient 방향으로 움직여서 빨간 구역(Loss = 0)에 도달하는 것을 목표로 한다.

손실 함수 $L(W)$를  파라미터 $W$에 대해 미분하면, 각 요소에서의 기울기(편미분 값)가 나오고 이를 모두 모아놓은 것이 Gradient이다. Gradient 벡터는 손실 함수가 가장 크게 증가하는 방향을 가리키며, 따라서 경사하강법에서는 그 반대 방향인 $-∇L(W)$으로 이동하여 손실을 줄인다. 

Gradient 벡터는 단순히 기울기의 모음이 아니라, 함수의 접선 방향을 나타내고, 이를 공간 속에서 보면 하나의 선분으로 해석된다.

경사하강법은 이러한 Gradient를 활용해 반복적으로 파라미터를 갱신하며 최적의 $W$를 찾아가는 과정이다. 구체적으로는 현재 파라미터 $W^{(t)}$에서 Gradient $\nabla L(W^{(t)})$를 계산한 뒤,

$W^{(t+1)} = W^{(t)} - \eta \nabla L(W^{(t)})$

와 같은 규칙으로 업데이트한다. 여기서 **$\eta$는 학습률(learning rate / 하이퍼파라미터)**로, 한 번의 이동 크기를 조절한다. 이 과정을 반복하면 파라미터가 점차 손실을 줄이는 방향으로 이동하고, 결국 Gradient가 0에 가까워지는 지점, 즉 손실 함수가 최소가 되는 최적의 $W$에 수렴하게 된다.

### 디버깅 전략

Numerical gradient: 파라미터 $W$의 각 요소를 아주 조금 변화시킨 뒤, 그때 손실 함수 $L(W)$값이 얼마나 변하는지 계산하여 기울기를 근사하는 방식 (단순, 느림, 부정확함)

Analytic gradient: 미분 공식을 직접 적용하여 수식으로 gradient를 계산하는 방식 (빠름, 정확, 에러 발생 쉬움)

실제 학습에서는 Analytic(해석적) Gradient만 사용한다. 하지만 내가 짠 Gradient 계산 코드가 올바른지 디버깅을 할 때는 Numerical(수치적) Gradient를 사용하기도 한다. 

(a) 코드: 해석적 Gradient
(b) 코드: 수치적 Gradient
이 두 결과를 비교하고 값이 거의 일치한다면 코드가 올바르다고 판단할 수 있다.

다만 수치적 Gradient는 느리기 때문에 디버깅을 할 때는 파라미터 크기를 줄이고 간단한 모델에만 적용하는 것이 좋다.

### Stochastic Gradient Descent (SGD)

![image.png](32f35391-d4cf-4927-9c5a-3d26688f94c0.png)

전체 Loss의 Gradient를 구하려면, 전체 데이터셋에 있는 모든 개별 데이터의 손실에 대한 경사도를 각각 구한 뒤, 그 값들을 모두 더하고 평균을 내야 한다. 하지만 훈련 데이터($N$)가 엄청나게 많을 경우, Gradient를 계산하는데 엄청나게 많은 연산이 필요하게 된다.

이러한 문제를 해결하기 위해 **Stochastic Gradient Descent (SGD)**라는 방법을 사용한다. 전체 데이터 셋에서의 Loss와 Gradient를 계산하기 보다는 **Minibatch**라는 작은 트레이닝 샘플로 나눠서 학습하는 것이다.

보통 Minibatch는 32, 64, 128과 같은 2의 제곱수로 정한다. 전체 데이터 대신 임의로 뽑은 소수 데이터를 사용하여 Gradient가 매번 바뀌지만, 여러번 반복하다보면 전체 데이터에서 얻는 Gradient와 비슷해진다. 

이는 마치 Monte Carlo Method의 샘플링을 통해 전체 분포를 추정하는 것과 유사하다.

![image.png](0f00db61-3390-4232-b818-b6861aa6742c.png)

`data_batch`에 샘플 훈련 데이터 256개를 저장한다.
`evaluate_gradient()`를 통해 현재 weights에서 loss function의 기울기를 계산해 gradient를 구한다.

Loss가 줄어드는 방향으로 weights를 수정한다.

더 이해 필요

# 3. Image Features

![image.png](image%2022.png)

실제로 이미지 자체를 입력 데이터로 사용하는 것은 좋지 않다. 그래서 이미지의 특징을 뽑아서 연결하여 하나의 특징 벡터를 입력 데이터로 사용한다.  이 방식은 모델이 복잡한 원시 픽셀 데이터를 직접 다루는 대신, 사람이 설계한 '특징(feature)'을 사용해 문제를 단순화했다.

![image.png](image%2023.png)

원형으로 분포된 데이터를 직선으로 나누는 것은 불가능하다. 그러나 이 데이터를 **극좌표계**라는 '특징'으로 변환하면, 데이터가 직선(Linear한 결정 경제)으로 분리 가능한 형태로 바뀌게 된다.

이처럼 **'특징 변환'**을 통해 데이터를 모델이 더 쉽게 학습할 수 있는 형태로 바꾸는 것이 이 접근법의 핵심이다. 이미지의 경우, 픽셀 값을 직접 사용하는 대신 색상, 질감, 윤곽선 등 이미지의 본질적인 정보를 담은 특징 벡터를 만들면 선형 분류기의 성능을 크게 향상시킬 수 있다.

## 3-1) Color Histogram

![image.png](image%2024.png)

이미지 전체의 색상 분포를 수치화한 것이다. 이미지가 어떤 색을 많이 포함하는지 알려준다.

## 3-2) Histogram of Oriented Gradients (HoG)

![image.png](image%2025.png)

이미지를 작은 영역으로 나누고, 각 영역의 엣지 방향 분포를 히스토그램으로 만든다. 이를 통해 이미지의 모양과 윤곽 정보를 포착한다.

## 3-3) Bag of Words

![image.png](image%2026.png)

자연어 처리에서 영감을 받은 기법으로, 이미지 조각들을 군집화하여 '시각 단어(visual words)'를 정의한 뒤, 이미지 내 시각 단어의 발생 빈도를 벡터로 만든다.

![image.png](image%2027.png)

CNN이나 DNN으로 넘어가면 위와 같이 이미 만들어 놓은 특징들을 쓰기 보다는 데이터로부터 특징들을 직접 학습하게 된다. 그렇기 때문에 원시 픽셀 데이터가 CNN에 그대로 들어가고 여러 레이어를 거쳐서 데이터를 통한 특징 표현을 직접 만들어 낸다.

즉 딥러닝은 ‘어떤 특징이 중요한지’를 모델 스스로가 판단하고 학습한다는 것이다.